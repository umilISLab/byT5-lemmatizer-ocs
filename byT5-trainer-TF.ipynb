{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8436a50",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "see README.md for details\n",
    "\n",
    "Loosely following this tutorial:\n",
    "https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a3775-0474-4e29-8b56-4215ad0a5a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:27:35.187747Z",
     "iopub.status.busy": "2024-07-18T12:27:35.187528Z",
     "iopub.status.idle": "2024-07-18T12:27:37.783021Z"
    }
   },
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe0dee-1ee6-41c8-9ebb-5d64ea9f93cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:23.195130Z",
     "iopub.status.busy": "2024-07-23T13:01:23.194745Z",
     "iopub.status.idle": "2024-07-23T13:01:30.559811Z",
     "shell.execute_reply": "2024-07-23T13:01:30.558756Z",
     "shell.execute_reply.started": "2024-07-23T13:01:23.195100Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from glob import glob\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import T5Config\n",
    "from transformers import TFT5ForConditionalGeneration\n",
    "from transformers import ByT5Tokenizer  # a \"dummy\" tokenizer, tokenizing into bytes\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from config import data_root, model_root, checkpoint_name\n",
    "from config import token_len, annot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf1d65-b9c0-4d65-acd4-de483927446e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.561884Z",
     "iopub.status.busy": "2024-07-23T13:01:30.561304Z",
     "iopub.status.idle": "2024-07-23T13:01:30.573222Z",
     "shell.execute_reply": "2024-07-23T13:01:30.572339Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.561884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader_config = DataLoaderConfiguration(\n",
    "    use_seedable_sampler=False,\n",
    ")\n",
    "accelerator = Accelerator(\n",
    "    dataloader_config=dataloader_config,\n",
    "    project_dir=model_root,\n",
    ")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "# device = accelerator.device\n",
    "torch.set_default_device(device)\n",
    "# torch.cuda.is_available()\n",
    "# accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4a3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.574538Z",
     "iopub.status.busy": "2024-07-23T13:01:30.574140Z",
     "iopub.status.idle": "2024-07-23T13:01:30.686287Z",
     "shell.execute_reply": "2024-07-23T13:01:30.685619Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.574518Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# for fname in glob(f\"{data_root}/*.csv\"):\n",
    "#     dfs += [pd.read_csv(fname, names=[\"inputs\", \"labels\"])]\n",
    "with zipfile.ZipFile(f\"{data_root}/data-ue.zip\") as zf:\n",
    "    for name in zf.namelist():\n",
    "        dfs += [pd.read_csv(zf.open(name), names=[\"input\", \"label\"])]\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.train_test_split(test_size=0.1, shuffle=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3368dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.687896Z",
     "iopub.status.busy": "2024-07-23T13:01:30.687672Z",
     "iopub.status.idle": "2024-07-23T13:01:33.527097Z",
     "shell.execute_reply": "2024-07-23T13:01:33.526409Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.687877Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = ByT5Tokenizer()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "\n",
    "\n",
    "# Create a tokenization function\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"input\"], max_length=64, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"label\"], max_length=64, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tds = ds.map(preprocess_function, batched=True)\n",
    "tds = tds.remove_columns([\"input\", \"label\"])\n",
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb82a7-efda-4e01-952e-2f5860603892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:33.528212Z",
     "iopub.status.busy": "2024-07-23T13:01:33.527982Z",
     "iopub.status.idle": "2024-07-23T13:01:34.062884Z",
     "shell.execute_reply": "2024-07-23T13:01:34.062138Z",
     "shell.execute_reply.started": "2024-07-23T13:01:33.528192Z"
    }
   },
   "outputs": [],
   "source": [
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_exact_match(pred: EvalPrediction):\n",
    "    # Convert predictions to text\n",
    "    predictions = pred.predictions\n",
    "    references = pred.label_ids\n",
    "\n",
    "    # Decode if needed\n",
    "    decoded_preds = [\n",
    "        pred.decode(pred, skip_special_tokens=True) for pred in predictions\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        label.decode(label, skip_special_tokens=True) for label in references\n",
    "    ]\n",
    "\n",
    "    # Compute exact match\n",
    "    result = exact_match_metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels\n",
    "    )\n",
    "    return {\"exact_match\": result[\"exact_match\"]}\n",
    "\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_root}/byT5-ocs-ue\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #     gradient_checkpointing=True,\n",
    "    # torch_empty_cache_steps=100,\n",
    "    disable_tqdm=False,\n",
    "    report_to=None,  # disable wandb.ai\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    model = TFT5ForConditionalGeneration(config)\n",
    "    # model = model.cuda()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "config = T5Config.from_pretrained(\"t5-base\")\n",
    "# config.task_specific_params = {}\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c98697-ef34-49f7-bcd0-384ede558491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:34.064220Z",
     "iopub.status.busy": "2024-07-23T13:01:34.063981Z",
     "iopub.status.idle": "2024-07-23T13:01:37.433265Z",
     "shell.execute_reply": "2024-07-23T13:01:37.432635Z",
     "shell.execute_reply.started": "2024-07-23T13:01:34.064198Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=init_model,\n",
    "    args=args,\n",
    "    train_dataset=tds[\"train\"],\n",
    "    eval_dataset=tds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_exact_match,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd1633-8da7-482c-9200-640a1d45b6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:37.434792Z",
     "iopub.status.busy": "2024-07-23T13:01:37.434027Z",
     "iopub.status.idle": "2024-07-23T13:01:56.440713Z",
     "shell.execute_reply": "2024-07-23T13:01:56.438797Z",
     "shell.execute_reply.started": "2024-07-23T13:01:37.434792Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fd845",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-23T13:01:56.441571Z",
     "iopub.status.idle": "2024-07-23T13:01:56.441869Z",
     "shell.execute_reply": "2024-07-23T13:01:56.441757Z",
     "shell.execute_reply.started": "2024-07-23T13:01:56.441757Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=f\"{model_root}/byT5-ocs-ue-final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
