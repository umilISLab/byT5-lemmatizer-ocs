{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8436a50",
   "metadata": {},
   "source": [
    "# Training a model with custom DataLoader\n",
    "meant to handle problems with placing generator on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe0dee-1ee6-41c8-9ebb-5d64ea9f93cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from glob import glob\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import wandb\n",
    "from datasets import Dataset as HFDataset\n",
    "from evaluate import load\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import T5Config\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import ByT5Tokenizer  # a \"dummy\" tokenizer, tokenizing into bytes\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from config import data_root, model_root, checkpoint_name\n",
    "from config import token_len, annot_len\n",
    "from config import device as device_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcf1d65-b9c0-4d65-acd4-de483927446e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/accelerate/main/en/package_reference/utilities#accelerate.DataLoaderConfiguration\n",
    "dataloader_config = DataLoaderConfiguration(\n",
    "    use_seedable_sampler=False,\n",
    ")\n",
    "# https://huggingface.co/docs/accelerate/main/en/package_reference/accelerator#accelerate.Accelerator\n",
    "accelerator = Accelerator(\n",
    "    dataloader_config=dataloader_config,\n",
    "    project_dir=model_root,\n",
    "    # rng_types=\"torch\",\n",
    "    # rng_types=\"cuda\",\n",
    "    # rng_types=\"generator\",\n",
    "    cpu=device_choice == \"cpu\",\n",
    ")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "device = accelerator.device\n",
    "torch.set_default_device(device)\n",
    "# torch.cuda.is_available()\n",
    "# accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f4a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# for fname in glob(f\"{data_root}/*.csv\"):\n",
    "#     dfs += [pd.read_csv(fname, names=[\"inputs\", \"labels\"])]\n",
    "with zipfile.ZipFile(f\"{data_root}/data-ue.zip\") as zf:\n",
    "    for name in zf.namelist():\n",
    "        dfs += [pd.read_csv(zf.open(name), names=[\"input\", \"label\"])]\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3368dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/model_doc/byt5#transformers.ByT5Tokenizer\n",
    "tokenizer = ByT5Tokenizer()\n",
    "\n",
    "\n",
    "# Function to tokenize data\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"text\"], max_length=16, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            examples[\"target\"], max_length=16, truncation=True, padding=\"max_length\"\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = [\n",
    "        -100 if token == tokenizer.pad_token_id else token\n",
    "        for token in model_inputs[\"labels\"]\n",
    "    ]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Create Hugging Face Dataset\n",
    "data = {\"text\": df[\"input\"].to_list(), \"target\": df[\"label\"].to_list()}\n",
    "hf_dataset = HFDataset.from_dict(data)\n",
    "\n",
    "# Tokenize dataset\n",
    "tokenized_dataset = hf_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"target\"]\n",
    ")\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58909e-64d4-4458-885a-22901de06e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom DataLoader\n",
    "class HFDatasetWrapper(torch.utils.data.Dataset):\n",
    "    def __init__(self, hf_dataset):\n",
    "        self.dataset = hf_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "\n",
    "wrapped_dataset = HFDatasetWrapper(tokenized_dataset)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(\n",
    "    wrapped_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator\n",
    ")\n",
    "\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eb82a7-efda-4e01-952e-2f5860603892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/spaces/evaluate-metric/exact_match\n",
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "\n",
    "def compute_exact_match(pred: EvalPrediction):\n",
    "    # Convert predictions to text\n",
    "    predictions = pred.predictions\n",
    "    references = pred.label_ids\n",
    "\n",
    "    # Decode if needed\n",
    "    decoded_preds = [\n",
    "        pred.decode(pred, skip_special_tokens=True) for pred in predictions\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        label.decode(label, skip_special_tokens=True) for label in references\n",
    "    ]\n",
    "\n",
    "    # Compute exact match\n",
    "    result = exact_match_metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels\n",
    "    )\n",
    "    return {\"exact_match\": result[\"exact_match\"]}\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainingArguments\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_root}/byT5-ocs-ue\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    # use_cache=False,\n",
    "    torch_empty_cache_steps=100,\n",
    "    disable_tqdm=False,\n",
    "    report_to=None,  # disable wandb.ai\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1,\n",
    "    eval_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5ForConditionalGeneration\n",
    "def init_model():\n",
    "    model = T5ForConditionalGeneration(config)\n",
    "    # model = model.cuda()\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/model_doc/t5#transformers.T5Config\n",
    "config = T5Config.from_pretrained(\"t5-base\")\n",
    "# config.task_specific_params = {}\n",
    "# https://huggingface.co/docs/transformers/main_classes/data_collator#transformers.DataCollatorForSeq2Seq\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(\n",
    "    wrapped_dataset, batch_size=batch_size, shuffle=False, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c98697-ef34-49f7-bcd0-384ede558491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Seq2SeqTrainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return dataloader\n",
    "\n",
    "\n",
    "# https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Seq2SeqTrainer\n",
    "trainer = CustomTrainer(\n",
    "    model_init=init_model,\n",
    "    args=args,\n",
    "    train_dataset=wrapped_dataset,\n",
    "    eval_dataset=wrapped_dataset,  # TODO\n",
    "    # train_dataset=wrapped_dataset[\"train\"],\n",
    "    # eval_dataset=wrapped_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_exact_match,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cd1633-8da7-482c-9200-640a1d45b6bf",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fd845",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=f\"{model_root}/byT5-ocs-ue-final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
