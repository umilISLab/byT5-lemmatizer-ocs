{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8436a50",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "see README.md for details\n",
    "\n",
    "Loosely following this tutorial:\n",
    "https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a3775-0474-4e29-8b56-4215ad0a5a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:27:35.187747Z",
     "iopub.status.busy": "2024-07-18T12:27:35.187528Z",
     "iopub.status.idle": "2024-07-18T12:27:37.783021Z"
    }
   },
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebe0dee-1ee6-41c8-9ebb-5d64ea9f93cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:23.195130Z",
     "iopub.status.busy": "2024-07-23T13:01:23.194745Z",
     "iopub.status.idle": "2024-07-23T13:01:30.559811Z",
     "shell.execute_reply": "2024-07-23T13:01:30.558756Z",
     "shell.execute_reply.started": "2024-07-23T13:01:23.195100Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 13:01:26.905279: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 13:01:26.905358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 13:01:26.907057: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 13:01:26.916273: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 13:01:28.241970: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import pandas as pd\n",
    "# from glob import glob\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "from accelerate import Accelerator, DataLoaderConfiguration\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import T5Config\n",
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import ByT5Tokenizer  # a \"dummy\" tokenizer, tokenizing into bytes\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "from config import data_root, model_root, checkpoint_name\n",
    "from config import token_len, annot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcf1d65-b9c0-4d65-acd4-de483927446e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.561884Z",
     "iopub.status.busy": "2024-07-23T13:01:30.561304Z",
     "iopub.status.idle": "2024-07-23T13:01:30.573222Z",
     "shell.execute_reply": "2024-07-23T13:01:30.572339Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.561884Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader_config = DataLoaderConfiguration(\n",
    "    use_seedable_sampler=False,\n",
    ")\n",
    "accelerator = Accelerator(\n",
    "    dataloader_config=dataloader_config,\n",
    "    project_dir=model_root,\n",
    ")\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "# device = accelerator.device\n",
    "torch.set_default_device(device)\n",
    "# torch.cuda.is_available()\n",
    "# accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f4a3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.574538Z",
     "iopub.status.busy": "2024-07-23T13:01:30.574140Z",
     "iopub.status.idle": "2024-07-23T13:01:30.686287Z",
     "shell.execute_reply": "2024-07-23T13:01:30.685619Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.574518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'label', '__index_level_0__'],\n",
       "        num_rows: 36993\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input', 'label', '__index_level_0__'],\n",
       "        num_rows: 4111\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "# for fname in glob(f\"{data_root}/*.csv\"):\n",
    "#     dfs += [pd.read_csv(fname, names=[\"inputs\", \"labels\"])]\n",
    "with zipfile.ZipFile(f\"{data_root}/data-ue.zip\") as zf:\n",
    "    for name in zf.namelist():\n",
    "        dfs += [pd.read_csv(zf.open(name), names=[\"input\", \"label\"])]\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.train_test_split(test_size=0.1,shuffle=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3368dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:30.687896Z",
     "iopub.status.busy": "2024-07-23T13:01:30.687672Z",
     "iopub.status.idle": "2024-07-23T13:01:33.527097Z",
     "shell.execute_reply": "2024-07-23T13:01:33.526409Z",
     "shell.execute_reply.started": "2024-07-23T13:01:30.687877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b53198cfc6c4e949c331d7587ccb827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36993 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4016: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175b0e6cfad44789802fdf003aec4538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 36993\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['__index_level_0__', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 4111\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ByT5Tokenizer()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "\n",
    "# Create a tokenization function\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"input\"], max_length=64, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"label\"], max_length=64, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tds = ds.map(preprocess_function, batched=True)\n",
    "tds = tds.remove_columns([\"input\", \"label\"])\n",
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24eb82a7-efda-4e01-952e-2f5860603892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:33.528212Z",
     "iopub.status.busy": "2024-07-23T13:01:33.527982Z",
     "iopub.status.idle": "2024-07-23T13:01:34.062884Z",
     "shell.execute_reply": "2024-07-23T13:01:34.062138Z",
     "shell.execute_reply.started": "2024-07-23T13:01:33.528192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "def compute_exact_match(pred: EvalPrediction):\n",
    "    # Convert predictions to text\n",
    "    predictions = pred.predictions\n",
    "    references = pred.label_ids\n",
    "    \n",
    "    # Decode if needed\n",
    "    decoded_preds = [pred.decode(pred, skip_special_tokens=True) for pred in predictions]\n",
    "    decoded_labels = [label.decode(label, skip_special_tokens=True) for label in references]\n",
    "    \n",
    "    # Compute exact match\n",
    "    result = exact_match_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"exact_match\": result[\"exact_match\"]}\n",
    "\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_root}/byT5-ocs-ue\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #     gradient_checkpointing=True,\n",
    "    # torch_empty_cache_steps=100,\n",
    "    disable_tqdm=False,\n",
    "    report_to=None,  # disable wandb.ai\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit = 1,\n",
    "    eval_strategy=\"steps\",\n",
    ")\n",
    "\n",
    "def init_model():\n",
    "    model = T5ForConditionalGeneration(config)\n",
    "    # model = model.cuda()\n",
    "    model.to(device)\n",
    "    return model\n",
    "    \n",
    "config = T5Config.from_pretrained(\"t5-base\")\n",
    "# config.task_specific_params = {}\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c98697-ef34-49f7-bcd0-384ede558491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:34.064220Z",
     "iopub.status.busy": "2024-07-23T13:01:34.063981Z",
     "iopub.status.idle": "2024-07-23T13:01:37.433265Z",
     "shell.execute_reply": "2024-07-23T13:01:37.432635Z",
     "shell.execute_reply.started": "2024-07-23T13:01:34.064198Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model_init=init_model,\n",
    "    args=args,\n",
    "    train_dataset=tds[\"train\"],\n",
    "    eval_dataset=tds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_exact_match,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cd1633-8da7-482c-9200-640a1d45b6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T13:01:37.434792Z",
     "iopub.status.busy": "2024-07-23T13:01:37.434027Z",
     "iopub.status.idle": "2024-07-23T13:01:56.440713Z",
     "shell.execute_reply": "2024-07-23T13:01:56.438797Z",
     "shell.execute_reply.started": "2024-07-23T13:01:37.434792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-23 13:01:41,200] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='27744' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    4/27744 00:04 < 18:24:36, 0.42 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fd845",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-23T13:01:56.441571Z",
     "iopub.status.idle": "2024-07-23T13:01:56.441869Z",
     "shell.execute_reply": "2024-07-23T13:01:56.441757Z",
     "shell.execute_reply.started": "2024-07-23T13:01:56.441757Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir=f\"{model_root}/byT5-ocs-ue-final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
