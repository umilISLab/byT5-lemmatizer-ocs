{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8436a50",
   "metadata": {},
   "source": [
    "# Training a model\n",
    "see README.md for details\n",
    "\n",
    "Loosely following this tutorial:\n",
    "https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aebe0dee-1ee6-41c8-9ebb-5d64ea9f93cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:55:23.168258Z",
     "iopub.status.busy": "2024-07-15T15:55:23.167805Z",
     "iopub.status.idle": "2024-07-15T15:55:30.593123Z",
     "shell.execute_reply": "2024-07-15T15:55:30.592542Z",
     "shell.execute_reply.started": "2024-07-15T15:55:23.168239Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import T5Config\n",
    "from transformers import    T5ForConditionalGeneration\n",
    "from transformers import ByT5Tokenizer  # a \"dummy\" tokenizer, tokenizing into bytes\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "from config import data_root, model_root, checkpoint_name\n",
    "from config import token_len, annot_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bcf1d65-b9c0-4d65-acd4-de483927446e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:55:30.594569Z",
     "iopub.status.busy": "2024-07-15T15:55:30.594150Z",
     "iopub.status.idle": "2024-07-15T15:55:30.599692Z",
     "shell.execute_reply": "2024-07-15T15:55:30.599171Z",
     "shell.execute_reply.started": "2024-07-15T15:55:30.594525Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f4a3d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:55:35.835841Z",
     "iopub.status.busy": "2024-07-15T15:55:35.835062Z",
     "iopub.status.idle": "2024-07-15T15:55:35.855998Z",
     "shell.execute_reply": "2024-07-15T15:55:35.855551Z",
     "shell.execute_reply.started": "2024-07-15T15:55:35.835812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inputs', 'labels'],\n",
       "        num_rows: 318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['inputs', 'labels'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for fname in glob(f\"{data_root}/*.csv\"):\n",
    "    dfs += [pd.read_csv(fname, names=[\"inputs\", \"labels\"])]\n",
    "df = pd.concat(dfs, axis=0)\n",
    "\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.train_test_split(test_size=0.1)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3368dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0731a912f2461ea16260db92f7af34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/318 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3eb7784b59b41808cf9b18710d15991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ByT5Tokenizer()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "\n",
    "\n",
    "# Create a tokenization function\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"inputs\"]\n",
    "    targets = examples[\"labels\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=64, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=64, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Apply the tokenization function to the dataset\n",
    "tds = ds.map(preprocess_function, batched=True)\n",
    "tds = tds.remove_columns([\"inputs\"])\n",
    "tds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24eb82a7-efda-4e01-952e-2f5860603892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:55:39.701958Z",
     "iopub.status.busy": "2024-07-15T15:55:39.701458Z",
     "iopub.status.idle": "2024-07-15T15:55:43.130357Z",
     "shell.execute_reply": "2024-07-15T15:55:43.129764Z",
     "shell.execute_reply.started": "2024-07-15T15:55:39.701936Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "exact_match_metric = load(\"exact_match\")\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_root}/byT5-ocs-ue\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    #     gradient_checkpointing=True,\n",
    "    # torch_empty_cache_steps=100,\n",
    "    disable_tqdm=False,\n",
    "    report_to=None,  # disable wandb.ai\n",
    ")\n",
    "\n",
    "config = T5Config.from_pretrained(\"t5-base\")\n",
    "# config.task_specific_params = {}\n",
    "model = T5ForConditionalGeneration(config)\n",
    "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c98697-ef34-49f7-bcd0-384ede558491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:56:10.167944Z",
     "iopub.status.busy": "2024-07-15T15:56:10.167719Z",
     "iopub.status.idle": "2024-07-15T15:56:11.815154Z",
     "shell.execute_reply": "2024-07-15T15:56:11.814603Z",
     "shell.execute_reply.started": "2024-07-15T15:56:10.167927Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tds[\"train\"],\n",
    "    eval_dataset=tds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=exact_match_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53cd1633-8da7-482c-9200-640a1d45b6bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T15:56:17.372745Z",
     "iopub.status.busy": "2024-07-15T15:56:17.372507Z",
     "iopub.status.idle": "2024-07-15T15:56:18.125324Z",
     "shell.execute_reply": "2024-07-15T15:56:18.124543Z",
     "shell.execute_reply.started": "2024-07-15T15:56:17.372720Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 318\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 237\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [237/237 09:47, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=237, training_loss=2.031089557374077, metrics={'train_runtime': 589.9212, 'train_samples_per_second': 1.617, 'train_steps_per_second': 0.402, 'total_flos': 20654614702080.0, 'train_loss': 2.031089557374077, 'epoch': 2.99})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10fd845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 318\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 36\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
